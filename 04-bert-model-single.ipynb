{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3f704f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n",
      "4.20.0.dev0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import torch \n",
    "print(torch.__version__)\n",
    "import transformers\n",
    "print(transformers.__version__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97c24e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import WeightedRandomSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c00023",
   "metadata": {},
   "source": [
    "## Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a303a949",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# specify where the model docs are, note that you added \"model_type\":\"bert\" in line 1 of json file\n",
    "tokenizer = AutoTokenizer.from_pretrained('../model/UCSF BERT-500k+275k-pytorch/', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2638a5b4",
   "metadata": {},
   "source": [
    "## Parragraph/doc level classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a332dd88",
   "metadata": {},
   "source": [
    "1. Preparing classification dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7402b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadNotes(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4b8ee6",
   "metadata": {},
   "source": [
    "\n",
    "from torch import nn\n",
    "from transformers import Trainer\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss (suppose one has 3 labels with different weights)\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([class_weights[1], \n",
    "                                                            class_weights[0]]))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84441492",
   "metadata": {},
   "source": [
    "1.1 Get train, dev and test set texts and labels. Best way to do this is to load through csv or dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff9b52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = '../data_200/recombined/'\n",
    "dataList = os.listdir(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce07166f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e4619235808eee774f5728d</td>\n",
       "      <td>Distended stomach and proximal duodenum, sim...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ebd8129c206f20a8b300bfe</td>\n",
       "      <td>***** of the enteric tube terminates within ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5fddef39eaf0903792b27112</td>\n",
       "      <td>Unremarkable  Pelvis: Unremarkable  \\r\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5f5aaa30d8d9aa5228b83083</td>\n",
       "      <td>No bowel obstruction. Small fat-containing u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5e463dc95808eee774ab89b0</td>\n",
       "      <td>Colonic diverticulosis.  Pelvis: Unremarkable...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        idx  \\\n",
       "0  5e4619235808eee774f5728d   \n",
       "1  5ebd8129c206f20a8b300bfe   \n",
       "2  5fddef39eaf0903792b27112   \n",
       "3  5f5aaa30d8d9aa5228b83083   \n",
       "4  5e463dc95808eee774ab89b0   \n",
       "\n",
       "                                            sentence  label  \n",
       "0    Distended stomach and proximal duodenum, sim...      0  \n",
       "1    ***** of the enteric tube terminates within ...      0  \n",
       "2          Unremarkable  Pelvis: Unremarkable  \\r\\n       0  \n",
       "3    No bowel obstruction. Small fat-containing u...      0  \n",
       "4   Colonic diverticulosis.  Pelvis: Unremarkable...      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abFinds_liver = pd.read_csv(dataPath + dataList[0])\n",
    "abFinds_pancreas = pd.read_csv(dataPath + dataList[2])\n",
    "# fix labels\n",
    "abFinds_liver['label'] = [abFinds_liver['label'][j][2:-2]for j,i in enumerate(abFinds_liver['label'])]\n",
    "abFinds_pancreas['label'] = [abFinds_pancreas['label'][j][2:-2]for j,i in enumerate(abFinds_pancreas['label'])]\n",
    "\n",
    "# map to ints\n",
    "binaryMap = {'Present': 1, 'Absent': 0}\n",
    "abFinds_liver['label'] = abFinds_liver['label'].map(binaryMap)\n",
    "abFinds_pancreas['label'] = abFinds_pancreas['label'].map(binaryMap)\n",
    "\n",
    "# concatenate abnormal findings for pancreas + liver\n",
    "abnormal_findings = pd.concat([abFinds_liver, abFinds_pancreas])\n",
    "abnormal_findings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e970fb4",
   "metadata": {},
   "source": [
    "2. Trying the train_test_split method from sklearn with a pandas dataframe passed in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19cea249",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_abfinds = abnormal_findings['sentence']\n",
    "y_abfinds = abnormal_findings['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_abfinds, y_abfinds, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e4b872c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Present, Absent) -- Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(42, 258)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"(Present, Absent) -- Training\")\n",
    "sum(y_train[y_train == 1]), len(y_train[y_train != 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93f45441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Present, Absent) -- Testing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 90)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"(Present, Absent) -- Testing\")\n",
    "sum(y_test[y_test == 1]), len(y_test[y_test != 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a25192",
   "metadata": {},
   "source": [
    "**Note**\n",
    "- Important to show this as a key step in presentation.\n",
    "- A good idea would be to show how the regeneration of the splits changes the performance of the algorithm.\n",
    "- Keep for now liver and pancreas for all 5 applications\n",
    "- Analyze all performances and compare. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99297ae6",
   "metadata": {},
   "source": [
    "2.1 Adding weights to each class to introduce low dist. penalization.\n",
    "Resources used: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e762fa10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_sample_count = np.array(\n",
    "    [len(np.where(y_train == t)[0]) for t in np.unique(y_train)])\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in y_train])\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weigth = samples_weight.double()\n",
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cfb50b",
   "metadata": {},
   "source": [
    "3. Using tokenizer for the data we just split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8652d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding texts with the tokenizer\n",
    "train_encodings = tokenizer(X_train.tolist(), max_length = 512, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(X_test.tolist(), max_length=512, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02464c7",
   "metadata": {},
   "source": [
    "4. Create a dataset from the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2335ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RadNotes(train_encodings, y_train.tolist())\n",
    "val_dataset = RadNotes(val_encodings, y_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2b319b",
   "metadata": {},
   "source": [
    "5. Now specify training parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c79e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 3\n",
    "learning_rate = 5e-5\n",
    "warmup_steps = 0 # what is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5176f610",
   "metadata": {},
   "source": [
    "6. Now the training classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2ed9ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../model/UCSF BERT-500k+275k-pytorch/ were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../model/UCSF BERT-500k+275k-pytorch/ and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/silviamiramontes/opt/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# importing some more dependencies\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# now choosing GPU if available, if not choosing CPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# now for the model---- load\n",
    "model = AutoModelForSequenceClassification.from_pretrained('../model/UCSF BERT-500k+275k-pytorch/') \n",
    "model.to(device) # model moved to available device\n",
    "model.train() # set to training mode\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "num_steps = len(train_loader) // n_epochs #total training in batch div by num of epochs\n",
    "\n",
    "# optimization\n",
    "optim =AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "                optim, num_warmup_steps = warmup_steps, num_training_steps = num_steps\n",
    "            )\n",
    "\n",
    "# iterate for training\n",
    "for epoch in range(n_epochs): # for each available epoch\n",
    "    for batch in train_loader: # for b in train_loader\n",
    "        optim.zero_grad() # gradient @ zero?\n",
    "        input_ids = batch['input_ids'].to(device) # keeping track of ids in device\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        # save loss from the outputs of the model\n",
    "        loss=outputs[0]\n",
    "        \n",
    "        # now backprop\n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        scheduler.step() # updating learning rate schedule \n",
    "        model.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc85371",
   "metadata": {},
   "source": [
    "7. Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1a157ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "model.eval()\n",
    "\n",
    "preds, all_labels = None, None\n",
    "\n",
    "for batch in val_loader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    \n",
    "    outputs = model(input_ids, attention_mask = attention_mask)\n",
    "    logits = outputs.logits\n",
    "    \n",
    "    if preds is None:\n",
    "        preds = logits.detach().cpu().numpy()\n",
    "        all_labels = batch['labels'].detach().cpu().numpy()\n",
    "    else:\n",
    "        preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "        all_labels = np.append(all_labels, batch['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "preds = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3623021a",
   "metadata": {},
   "source": [
    "8. Computing evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42c6d8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  {'acc': 0.83, 'f1': 0.1904761904761905, 'precision': 0.18181818181818182, 'recall': 0.2, 'micro_f1': 0.83, 'macro_f1': 0.5477520617185422, 'macro_weighted_f1': 0.8335727587124235, 'macro_precision': 0.5459652706843718, 'macro_weighted_precision': 0.8372829417773238, 'macro_recall': 0.55, 'macro_weighted_recall': 0.83, 'confusion_matrix': array([[81,  9],\n",
      "       [ 8,  2]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/silviamiramontes/opt/anaconda3/lib/python3.8/site-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute evaluation metrics\n",
    "# Define desirable evaluation metrics\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from transformers.data.metrics import simple_accuracy\n",
    "\n",
    "def multiclass_acc_and_f1(preds, labels):\n",
    "    acc = simple_accuracy(preds, labels)\n",
    "    f1 = f1_score(y_true=labels, y_pred=preds, )\n",
    "    prec = precision_score(y_true=labels, y_pred=preds, )\n",
    "    recall = recall_score(y_true=labels, y_pred=preds, )\n",
    "    macro_f1 = f1_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    macro_weighted_f1 = f1_score(y_true=labels, y_pred=preds, average='weighted')\n",
    "    macro_precision = precision_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    macro_weighted_precision = precision_score(y_true=labels, y_pred=preds, average='weighted')\n",
    "    macro_recall = recall_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    macro_weighted_recall = recall_score(y_true=labels, y_pred=preds, average='weighted')\n",
    "    micro_f1 = f1_score(y_true=labels, y_pred=preds, average='micro')\n",
    "    confusion = confusion_matrix(y_true=labels, y_pred=preds)\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": recall,\n",
    "        'micro_f1': micro_f1,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"macro_weighted_f1\": macro_weighted_f1,\n",
    "        \"macro_precision\": macro_precision,\n",
    "        \"macro_weighted_precision\": macro_weighted_precision,\n",
    "        \"macro_recall\": macro_recall,\n",
    "        \"macro_weighted_recall\": macro_weighted_recall,\n",
    "        \"confusion_matrix\": confusion,\n",
    "    }\n",
    "\n",
    "result = multiclass_acc_and_f1(preds, all_labels)\n",
    "\n",
    "print(\"Result: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e088a674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0699b1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3645b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f9d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(result, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b97d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d9181",
   "metadata": {},
   "source": [
    "1. Testable hypothesis: combining classifiers, does that make them improve or worsen? (separate for each classifier)\n",
    "    - One model per organ, and compare by combining all classifiers \n",
    "    - good to test\n",
    "    - increased power will outweigh fact of us having less specificity\n",
    "2. Focus on Previous surgeries, abnormal findings, and disease_location\n",
    "3. Once we have a classifier\n",
    "    - LIT or tensorboard\n",
    "    - trying to understand the word enrichment in one group vs another\n",
    "        - f1 scores do not inform us much\n",
    "    - send him the list afterwards for his insight\n",
    "        - test outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddbd1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
